#!/usr/bin/env python3
# AIME 2024 — CoT + Code (single-shot) + Tree-of-Thought (branching) with cosine consensus
#
# WHAT THIS VERSION DOES
# ----------------------
# • The CODE method **only** asks the model to emit a PYCODE block that hardcodes the answer as:
#       print("__ANS__=<0..999>")
# • We **never execute** generated code.
# • We **strictly parse** the integer only from a valid PYCODE block that starts the output.
#   - If the output does not start with "PYCODE:", or the literal print is missing → CODE prediction = None.
#   - No tail scans. No CoT fallback. No guessing.
# • CoT path remains for comparison; ToT logic is left intact but made to use the same strict parsing.

import sys
import re
import math
import itertools
import collections
import traceback
from typing import Dict, Optional, List, Tuple
from collections import Counter

from vllm import LLM, SamplingParams

# -------- Load dataset (AIME 2024 only) --------
try:
    from aime_problems import AIME_2024_PROBLEMS  # list of {"question": str, "answer": str}
    print(f"✓ Loaded {len(AIME_2024_PROBLEMS)} real AIME 2024 problems")
except Exception as e:
    print(f"⚠️  WARNING: Could not load real AIME problems ({e}), using fallback dummy problems")
    AIME_2024_PROBLEMS = [
        {"question": "Compute 1+2+...+10.", "answer": "55"},
        {"question": "If 2x+3=17, find x.", "answer": "7"},
        {"question": "Find the remainder when 7^5 is divided by 100.", "answer": "7"},
        {"question": "A 9 km walk with a coffee break t minutes takes 4 hours at speed s, and 2h24m at speed s+2. If her speed is s+0.5, how many minutes does the trip take?", "answer": "204"},
    ]

# ========================= Utilities =========================

def _coerce_int(x) -> Optional[int]:
    try:
        if isinstance(x, bool): return None
        if isinstance(x, int):  return x
        if isinstance(x, float):
            r = round(x)
            return r if abs(x - r) < 1e-9 else None
        return int(str(x).strip())
    except Exception:
        return None

def _normalize_aime_int(x: Optional[int]) -> Optional[int]:
    """Valid AIME integer [0, 999] or None."""
    if x is None: return None
    try:
        xi = int(x)
        return xi if 0 <= xi <= 999 else None
    except Exception:
        return None

def extract_final_answer(text: str) -> Optional[int]:
    """Extract 'Final Answer: n' (for CoT only)."""
    patterns = [
        r"\*\*Final Answer[:\s]*([0-9]{1,3})\*\*",
        r"^\s*Final Answer[:\s]*([0-9]{1,3})\s*$",
        r"The final answer is[:\s]*([0-9]{1,3})",
        r"Answer[:\s]*([0-9]{1,3})",
        r"__ANS__\s*=\s*([0-9]{1,3})",
    ]
    for p in patterns:
        m = re.search(p, text, flags=re.IGNORECASE | re.MULTILINE)
        if m:
            v = _normalize_aime_int(_coerce_int(m.group(1)))
            if v is not None: return v
    # No tail-number heuristics here (we want CoT to be explicit too).
    return None

# --- STRICT PYCODE extraction (no execution, no guesses) ---

def extract_pycode_block_strict(text: Optional[str]) -> Optional[str]:
    """
    Accept only if the output **starts** with 'PYCODE:' (after whitespace).
    If 'ENDPYCODE' is present, extract the content between.
    If 'ENDPYCODE' is stripped by stop tokens, take everything after 'PYCODE:' line.
    """
    if not text:
        return None
    s = text.lstrip()
    if not s.startswith("PYCODE:"):
        return None

    # Try full 'PYCODE:' ... 'ENDPYCODE'
    m = re.search(r"^PYCODE:\s*\n(.*?)\nENDPYCODE\s*$", s, flags=re.DOTALL | re.IGNORECASE | re.MULTILINE)
    if m:
        return m.group(1).strip()

    # If ENDPYCODE was removed by stop, capture everything after the line
    m = re.search(r"^PYCODE:\s*\n(.*)$", s, flags=re.DOTALL | re.IGNORECASE | re.MULTILINE)
    if m:
        return m.group(1).strip()

    return None

def parse_hardcoded_ans_from_pycode(code_src: Optional[str]) -> Optional[int]:
    """
    ONLY accept a literal print line:
        print("__ANS__=<0..999>")
    No other patterns; no scanning outside PYCODE.
    """
    if not code_src:
        return None
    m = re.search(r'^\s*print\(\s*["\']__ANS__\s*=\s*([0-9]{1,3})["\']\s*\)\s*$', code_src, flags=re.MULTILINE)
    if not m:
        return None
    return _normalize_aime_int(_coerce_int(m.group(1)))

# --------- Cosine utilities (text + answer-consensus) ---------

def _tokenize(s: str) -> List[str]:
    return re.findall(r"[a-z0-9]+", s.lower())

def _tf_vector(s: str) -> Dict[str, float]:
    toks = _tokenize(s)
    if not toks: return {}
    c = Counter(toks)
    n = float(sum(c.values()))
    return {t: cnt / n for t, cnt in c.items()}

def cosine_text(a: str, b: str) -> float:
    va, vb = _tf_vector(a), _tf_vector(b)
    if not va or not vb: return 0.0
    keys = set(va) | set(vb)
    dot = sum(va.get(k, 0.0) * vb.get(k, 0.0) for k in keys)
    na = math.sqrt(sum(v*v for v in va.values()))
    nb = math.sqrt(sum(v*v for v in vb.values()))
    return 0.0 if na == 0.0 or nb == 0.0 else dot / (na * nb)

def _answer_vec(n: int) -> List[float]:
    h, t, o = n // 100, (n // 10) % 10, n % 10
    return [1.0, n/999.0, h/9.0, t/9.0, o/9.0]

def _cosine(u: List[float], v: List[float]) -> float:
    dot = sum(x*y for x, y in zip(u, v))
    nu = math.sqrt(sum(x*x for x in u))
    nv = math.sqrt(sum(y*y for y in v))
    return 0.0 if nu == 0.0 or nv == 0.0 else dot/(nu*nv)

def cosine_select_answer(cands: List[int]) -> Optional[int]:
    if not cands: return None
    vecs = [_answer_vec(c) for c in cands]
    m = [sum(v[i] for v in vecs)/len(vs) for i, vs in enumerate(zip(*vecs))]  # centroid
    sims = [(_cosine(v, m), c) for v, c in zip(vecs, cands)]
    sims.sort(key=lambda x: x[0], reverse=True)
    return sims[0][1]

# ========================= Model Wrapper =========================

class QwenRunner:
    def __init__(self, model_path: str = "openai/gpt-oss-120b"):
        print(f"Loading model: {model_path}")
        self.llm = LLM(
            model=model_path,
            trust_remote_code=True,
            tensor_parallel_size=1,
            gpu_memory_utilization=0.90,
            max_model_len=16384,
            dtype="bfloat16",
            enforce_eager=False,
            disable_log_stats=True,
            enable_prefix_caching=True,
            max_num_seqs=16,
        )
        # Deterministic single for CoT
        self.params_single = SamplingParams(
            temperature=0.0, top_p=1.0, repetition_penalty=1.05,
            n=1, max_tokens=1600
        )
        # Deterministic single for CODE with stop at ENDPYCODE
        self.params_code_single = SamplingParams(
            temperature=0.0, top_p=1.0, repetition_penalty=1.0,
            n=1, max_tokens=200, stop=["ENDPYCODE"]
        )
        print("✓ Model loaded\n")
        try:
            self.tok = self.llm.get_tokenizer()
        except Exception:
            self.tok = None

    def _build_prompt(self, messages: List[Dict[str, str]]) -> str:
        if self.tok is not None and hasattr(self.tok, "apply_chat_template"):
            return self.tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        prompt = ""
        for m in messages:
            role = m.get("role", "user"); content = m.get("content", "")
            prompt += f"<{role}>\n{content}\n</{role}>\n"
        prompt += "<assistant>\n"
        return prompt

    # Generic chat
    def generate_chat(self, messages: List[Dict[str, str]]) -> str:
        out = self.llm.generate([self._build_prompt(messages)], self.params_single)[0]
        return (out.outputs[0].text or "").strip() if out.outputs else ""

    # Multiple chat samples (for CoT branching)
    def generate_chat_multi(self, messages: List[Dict[str, str]],
                            n: int, temperature: float, top_p: float,
                            max_tokens: int) -> List[str]:
        params = SamplingParams(
            temperature=temperature, top_p=top_p, repetition_penalty=1.0,
            n=n, max_tokens=max_tokens
        )
        out = self.llm.generate([self._build_prompt(messages)], params)[0]
        return [(o.text or "").strip() for o in out.outputs if (o.text or "").strip()]

    # Code-only generations (with stop)
    def generate_code(self, messages: List[Dict[str, str]]) -> str:
        out = self.llm.generate([self._build_prompt(messages)], self.params_code_single)[0]
        return (out.outputs[0].text or "").strip() if out.outputs else ""

    def generate_code_multi(self, messages: List[Dict[str, str]],
                            n: int, temperature: float, top_p: float,
                            max_tokens: int) -> List[str]:
        params = SamplingParams(
            temperature=temperature, top_p=top_p, repetition_penalty=1.0,
            n=n, max_tokens=max_tokens, stop=["ENDPYCODE"]
        )
        out = self.llm.generate([self._build_prompt(messages)], params)[0]
        return [(o.text or "").strip() for o in out.outputs if (o.text or "").strip()]

# ========================= Prompts =========================

def cot_prompt(problem: str) -> List[Dict[str, str]]:
    return [
        {"role": "system", "content": "You are an AIME solver. Be correct, concise, and deterministic."},
        {"role": "user", "content": f"Solve the AIME problem with compact steps and end with exactly one line: Final Answer: n\n\nProblem:\n{problem}"},
    ]

def code_only_prompt(problem: str) -> List[Dict[str, str]]:
    """
    STRICT FORMAT. Your reply must begin with 'PYCODE:' as the very first characters,
    then Python code, and stop at 'ENDPYCODE'.
    REQUIREMENT inside the code:
        print("__ANS__=<integer in 0..999>")
    No variables, no f-strings, no concatenation, no extra prints, no commentary.
    """
    user_text = f"""Problem:
{problem}

Reply with ONLY this block, replacing 0 with the correct integer:

PYCODE:
print("__ANS__=0")
ENDPYCODE
"""
    return [
        {"role": "system", "content": "You are a precise Python code generator. Output ONLY the required code block; no analysis."},
        {"role": "user", "content": user_text},
    ]

# ========================= Single-shot Evaluation =========================

def evaluate_single(runner: QwenRunner, prob: Dict, index: int) -> Dict:
    q = prob["question"]; true_ans = int(prob["answer"])

    # CoT
    cot_text = runner.generate_chat(cot_prompt(q))
    cot_pred = extract_final_answer(cot_text)

    # CODE (strict, no execution, no fallback guesses)
    code_text = runner.generate_code(code_only_prompt(q))
    print(f"[RAW_CODE P{index:02d}]\n{code_text}\n" + "-"*70)

    code_src = extract_pycode_block_strict(code_text)
    if code_src is None:
        print(f"[WARN  P{index:02d}] CODE invalid: output does not start with 'PYCODE:' or block malformed.")
        code_pred = None
    else:
        code_pred = parse_hardcoded_ans_from_pycode(code_src)
        if code_pred is None:
            print(f"[WARN  P{index:02d}] CODE invalid: missing literal print(\"__ANS__=<int>\") inside PYCODE.")

    print(f"[TRACE P{index:02d}] CoT={cot_pred}  Code={code_pred}")
    return {
        "true": true_ans,
        "cot_pred": cot_pred,
        "code_pred": code_pred,
        "cot_ok": (cot_pred == true_ans) if cot_pred is not None else False,
        "code_ok": (code_pred == true_ans) if code_pred is not None else False,
    }

# ========================= ToT (Branching) =========================

def tot_cot_branching(runner: QwenRunner, problem: str, k: int, depth: int) -> Tuple[Optional[int], List[int]]:
    problem_txt = problem
    BeamItem = collections.namedtuple("BeamItem", ["scratch", "score"])
    beam: List[BeamItem] = [BeamItem(scratch="", score=0.0)]
    found_answers: List[int] = []

    for d in range(1, depth+1):
        next_items: List[BeamItem] = []
        print(f"    [CoT-Branch] depth {d}/{depth} | beam={len(beam)}")
        for item in beam:
            outs = runner.generate_chat_multi(
                [
                    {"role": "system", "content": "You are an AIME solver expanding a partial solution. Keep steps short and precise."},
                    {"role": "user", "content": f"""Problem:\n{problem_txt}\n\nScratch:\n{item.scratch or '(none)'}\n\nWrite ONE next step, or if solved output: Final Answer: n"""}
                ],
                n=k, temperature=0.7, top_p=0.9, max_tokens=200
            )
            for out in outs:
                ans = extract_final_answer(out)
                if ans is not None:
                    found_answers.append(ans)
                else:
                    new_scratch = (item.scratch + ("\n" if item.scratch else "") + out).strip()
                    sc = cosine_text(new_scratch, problem_txt)
                    next_items.append(BeamItem(new_scratch, sc))

        if next_items:
            next_items.sort(key=lambda z: z.score, reverse=True)
            beam = next_items[:k]
        else:
            if found_answers: break

    if found_answers:
        return cosine_select_answer(found_answers), found_answers
    return None, found_answers

def tot_code_branching(runner: QwenRunner, problem: str, k: int, depth: int) -> Tuple[Optional[int], List[int]]:
    """
    Code-ToT STRICT (no execution):
      - Sample k code generations.
      - Parse only if output starts with PYCODE and contains print("__ANS__=<int>").
      - Aggregate by cosine-to-centroid.
    """
    preds: List[int] = []
    outs = runner.generate_code_multi(code_only_prompt(problem), n=k, temperature=0.6, top_p=0.9, max_tokens=200)
    for i, o in enumerate(outs, 1):
        src = extract_pycode_block_strict(o)
        ans = parse_hardcoded_ans_from_pycode(src) if src else None
        print(f"      [Code-ToT] variant {i}: parsed -> {ans}")
        if ans is not None:
            preds.append(ans)

    if preds:
        return cosine_select_answer(preds), preds
    return None, preds

# ========================= Driver =========================

def evaluate_problem_tot(runner: QwenRunner, prob: Dict, index: int, k: int, depth: int = 3) -> Dict:
    q = prob["question"]; true_ans = int(prob["answer"])
    cot_pred, cot_all = tot_cot_branching(runner, q, k=k, depth=depth)
    code_pred, code_all = tot_code_branching(runner, q, k=k, depth=max(2, depth-1))
    print(f"[TRACE P{index:02d}] (ToT) COT cands={cot_all} → pick={cot_pred} | CODE cands={code_all} → pick={code_pred}")
    return {
        "true": true_ans,
        "cot_pred": cot_pred,
        "code_pred": code_pred,
        "cot_ok": (cot_pred == true_ans) if cot_pred is not None else False,
        "code_ok": (code_pred == true_ans) if code_pred is not None else False,
    }

def main():
    use_tot = "--tot" in sys.argv
    # k = branching factor and beam width (1..20)
    if "--k" in sys.argv:
        try:
            k = int(sys.argv[sys.argv.index("--k") + 1])
            if k < 1 or k > 20:
                print("K out of range [1,20]; defaulting to 6"); k = 6
        except Exception:
            k = 6
    else:
        k = 6
    # Optional depth
    if "--depth" in sys.argv:
        try:
            depth = int(sys.argv[sys.argv.index("--depth") + 1])
            depth = max(2, min(6, depth))
        except Exception:
            depth = 3
    else:
        depth = 3

    mode = f"ToT-Branching (beam={k}, depth={depth})" if use_tot else "Single-shot"
    print(f"🔥 AIME 2024 — CoT + Code — Mode: {mode}")
    print("=" * 70)

    runner = QwenRunner("openai/gpt-oss-120b")
    problems = AIME_2024_PROBLEMS

    cot_correct = 0
    code_correct = 0
    total = len(problems)

    for i, prob in enumerate(problems, 1):
        if use_tot:
            res = evaluate_problem_tot(runner, prob, i, k=k, depth=depth)
        else:
            res = evaluate_single(runner, prob, i)
        cot_correct += int(res["cot_ok"])
        code_correct += int(res["code_ok"])
        print(f"Problem {i:02d}: "
              f"COT={'✓' if res['cot_ok'] else '✗'}(pred={res['cot_pred']}, true={res['true']})  |  "
              f"CODE={'✓' if res['code_ok'] else '✗'}(pred={res['code_pred']}, true={res['true']})")

    cot_acc = 100.0 * cot_correct / total if total else 0.0
    code_acc = 100.0 * code_correct / total if total else 0.0
    print("\n=== FINAL ACCURACY ===")
    print(f"COT : {cot_correct}/{total}  = {cot_acc:.2f}%")
    print(f"CODE: {code_correct}/{total}  = {code_acc:.2f}%")
    print("======================")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print("Error:", e)
        traceback.print_exc()
